This document describes additional features which are not described in the root README.  

* ### Comparing segments
    When model data (```dmd```) is set, following method could be used to compare different segments
    of one feature.  
    ```python
    import data_fast_insights.calculations as calc
  
    comparison_example = calc.compare_intervals(selected='color_green', model_data=dmd)
    ```
    It's useful if we want to know what would happen from changing one feature of object to another.
* ### Calculating dependence of combinations of features:  
    * #### Partial combinations (combinations of a certain features with others) of size 2.  
        Construct binary feature combinations of the selected feature and every other one.
                These features equal 1 when all of its members equal 1.
                
        ```python
        dmd.construct_partial_combs(selected_feature, consider_selected_base=True)
        ```
        _**consider_selected_base** argument represents which column name will be considered as the base (parent) feature.
        This is important for future analysis and plots (functions in plotting module group by base column)._  
        
        Note that:
        > * :warning: It might produce a lot of small segments that are statistically unstable 
        (see "perc_of_total" in the model results)  

    * #### All combinations up to a certain combination size.  
        
        Binary feature combinations of sizes up to `comb_max_size` are constructed as binary features.
        These features equal 1 when all of its members equal 1.
        ```
        dmd.construct_combs_up_to(comb_max_size)
        ```
        Note that:
        > * plotting features generated by this method is not yet supported.
        > * :warning: It might produce a lot of small segments that are statistically unstable 
        (see "perc_of_total" in the model results)
        > * :warning: Using high comb_max_size values is computationally expensive  

    _These methods must be called after binary features are created_  

    #### Examples:  
    We have features
    - "x1", one of its values is "green"
    - "x2", one of its values is 10
    - "x3", one of its values is 120
    
    After conversion we will have binary features for these values that might look like:
    - "x1_green"
    - "x2_(-inf, 20]"
    - "x3_(-inf, 500]"
    
    Using dmd.construct_partial_combs("color", consider_base="selected") produces features:
    - "x1_green_AND_x2_(-inf, 20]", which equals 1 when "x1" is "green" and "x2" <= 20
    - "x1_green_AND_x3_(-inf, 500]"
    
    Using construct_combs_up_to(comb_max_size=2) instead would produce:
    - "x1_green_AND_x2_(-inf, 20]"
    - "x1_green_AND_x3_(-inf, 500]"
    - "x2_(-inf, 20]\_AND_x3_(-inf, 500]"  

* ### Visualizing in **plotting** module
    Main plotting method is `plot_segments_basic_info()`:  
    ```python
    fig = plot_segments_basic_info(model_data=dmd, res_low_df=res, base_feature_name='Longitude')
    ```
    _(where res_low_df is the result of calculate_dependence())_ 
       
    it shows segment size, importance and target mean for each segment.
    
    ![Segments Basic Plot](images/longitude_data_fast_insights_comments.png)  
      
    You can plot custom parameters with the following functions:  
        - plot_segments_dependence()  
        - plot_segments_central_tendency()  
     
    Plotting functions also return matplotlib figures which you can modify.
    
    For example:
    ```python
    fig = plot_segments_basic_info(model_data=dmd, res_low_df=res, base_feature_name='trial_period_avg')
    axs = fig.axes
    axs[0].set_title('Custom title', pad=50)
    axs[1].set_xlabel('Custom label')
    ```
    
    Notes: 
    - you might want to add this line to your notebook for better quality plots:
        ```python
        %config InlineBackend.figure_format = 'svg'
        ```
    - for now in Jupyter you have to assign a function call to a variable (or add ";" after a call),
        otherwise it'd show 2 plots. 
        ```python
        fig = plot_segments_basic_info(...)
        ```
* ### Experimental features  
    * #### Split-apply-combine type experiment.  
        Experiment in which data is first splitted by some dimension, 
        then a lot of small experiments are made, then the results are aggregated.
          
        **Why could this be useful?**  
        When magnitude of values varies a lot among the chosen dimension,
        this could be used to get normalized results.  
        **Requirements:**  
        Every subset after splitting has to still have variety in its values 
        (among other dimension).
        **Example:**  
        Sales of game keys. You could split sales by publisher, 
        but some publishers still have multiple games - there would be small experiments
        among games of the same publisher. 
        
        **Usage**  
        Instead of using BinaryDependenceModelData, we're using SplitApplyCombineModelData which is built on top of it
        ```python
        import pandas as pd
      
        from data_fast_insights.experimental import SplitApplyCombineModelData
        import data_fast_insights.calculations as calc
        from data_fast_insights.plotting import plot_segments_basic_info
        ```
      
        In the following lines we're setting data as in the usual Data Fast Insights experiment.
        ```python
        df_prep = ...
        cat_feats_ = ...
        num_feats_ = ...
        selected_target = ...
        ```
      
        First, we're making a global baseline experiment to get the required initial values 
        (such as categories/segments which will be used across all local experiments).    
        ```python
        sac_base = SplitApplyCombineModelData(
            total_data=df_prep, 
            cat_cols=cat_feats_, 
            num_cols=num_feats_, 
            y_name=selected_target, 
            y_type='mean')
        
        sac_base.global_num_bins = calc.make_bins(model_data=sac_base)
        sac_base.convert_to_binary(bins=sac_base.global_num_bins)
        
        res_base = calc.calculate_dependence(model_data=sac_base)
        ```
        
        Splitting by the required dimension.
        ```python
        sac_base.split('idProject')
        ```
        
        Filtering (in this case, excluding groups with less than 3 digital goods)
        ```python
        for project_id, part in sac_base.splitted.items():
            if part['data']['idDigitalGood'].nunique() < 3:
                print(f'Project {project_id} will be skipped')
                sac_base.splitted[project_id]['use_for_report'] = False
        ```
        
        Making local experiments on groups
        ```python
        sac_base.multiple_singular_experiments()
        ```
        
        Additionally filter groups again by any column from 
        [calculate_dependence()](data_fast_insights/calculations/_modelling.py) resulting dataframe
        (in this case, absolute size).  
        _This filtering is separate, because it's only available after local experiments_.
        ```python
        sac_base.filter_transpose_results({'total_sum': 200})
        ```
        Fill default values for features that are missing in some groups.
        ```python
        sac_base.fill_defaults()
        ```
        
        Finally, reduce and get the results.  
        _Note that there is an additional column in the result: `number_of_experiments` segment was in. 
        All local experiments use the categories/segments defined earlier in global experiments, 
        and not all of subgroups (projects in this example) will contain objects of those categories._
        ```
        sac_base.reduce()
        
        total_res_cut = sac_base.total_res.copy()
        
        total_res_cut = total_res_cut[total_res_cut['total_sum'] > 400]
        total_res_cut = total_res_cut[total_res_cut['perc_of_total'] > 10]
        total_res_cut = total_res_cut[total_res_cut['number_of_experiments'] >= 5]
        ```
        
        Plots are used in the same manner as for the usual experiment
        ```python
        f = plot_segments_basic_info(sac_base, sac_base.total_res, 'price_usd_current_min', 
                                     base_feature_rename='Minimum Price of the Item, USD')
        ```